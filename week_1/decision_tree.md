# Решающие деревья

Чаще всего используются для классификации

### Обучение

### ID3

```
ID3(Таблица примеров, Целевой признак, Признаки)
    Если все примеры положительны, то возвратить узел с меткой «+».
    Если все примеры отрицательны, то возвратить узел с меткой «-».
    Если множество признаков пустое, то возвратить узел с меткой, которая больше других встречается в значениях целевого признака в примерах.
    Иначе:
        A — признак, который лучше всего классифицирует примеры (с максимальной информационной выгодой).
        Создать корень дерева решения; признаком в корне будет являться A.
        Для каждого возможного значения A (vi):
            Добавить новую ветвь дерева ниже корня с узлом со значением  A=vi
            Выделить подмножество Examples(vi) примеров, у которых A=vi
            Если подмножество примеров пусто, то ниже этой новой ветви добавить узел с меткой, которая больше других встречается в значениях целевого признака в примерах.
            Иначе, ниже этой новой ветви добавить поддерево, вызывая рекурсивно ID3(Examples(vi), Целевой признак, Признаки)
    Возвратить корень.
```

#### Критерии ветвления

* Критерий Джини
* Критерий Донского

#### Достоинства 
 
* Интерпретируемость
* Допустимы разнотипные данные и данные с пропусками
* Вычислительная сложность построения - линейная по размеру выборки и количеству признаков
* Не бывает отказов от классификации
 
#### Недостатки

* Сложная структура дерева может привести к переобучению -> pruning
* Фрагментация выборки
* Чувствительность к шуму
* Зависимость от выбора критерия информативности

### CART

Обобщение ID3 на случай регрессии - в каждой терминальной вершине рассчитывается среднее значение элементов из обучающей выборки